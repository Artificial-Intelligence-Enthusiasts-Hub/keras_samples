{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка данных\n",
    "x_train = x_train.reshape((x_train.shape[0], -1)).astype('float32') / 255.0\n",
    "x_test = x_test.reshape((x_test.shape[0], -1)).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Создание модели\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(784,), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From d:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2623 - accuracy: 0.9243 - val_loss: 0.1459 - val_accuracy: 0.9577\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1136 - accuracy: 0.9665 - val_loss: 0.1106 - val_accuracy: 0.9672\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0785 - accuracy: 0.9756 - val_loss: 0.1023 - val_accuracy: 0.9690\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0580 - accuracy: 0.9817 - val_loss: 0.0937 - val_accuracy: 0.9729\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0449 - accuracy: 0.9854 - val_loss: 0.1079 - val_accuracy: 0.9699\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.0979 - val_accuracy: 0.9735\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.1130 - val_accuracy: 0.9716\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0266 - accuracy: 0.9910 - val_loss: 0.1105 - val_accuracy: 0.9737\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.1058 - val_accuracy: 0.9757\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.1401 - val_accuracy: 0.9676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d2a17ca680>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1197 - accuracy: 0.9721\n",
      "Test result: (0.11969930678606033, 0.972100019454956)\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test result: {test_loss, test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1063 - val_accuracy: 0.9782\n",
      "Epoch 2/3\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.1056 - val_accuracy: 0.9790\n",
      "Epoch 3/3\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.1189 - val_accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9983124732971191, 0.9994791746139526, 0.9997291564941406]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  11., 150., 253., 202.,  31.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  37., 251.,\n",
       "       251., 253., 107.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  21., 197., 251., 251., 253., 107.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 110., 190., 251.,\n",
       "       251., 251., 253., 169., 109.,  62.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0., 253., 251., 251., 251., 251., 253., 251., 251.,\n",
       "       220.,  51.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 182., 255., 253.,\n",
       "       253., 253., 253., 234., 222., 253., 253., 253.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  63., 221., 253., 251., 251., 251., 147.,  77.,  62.,\n",
       "       128., 251., 251., 105.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  32., 231., 251., 253.,\n",
       "       251., 220., 137.,  10.,   0.,   0.,  31., 230., 251., 243., 113.,\n",
       "         5.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  37., 251., 251., 253., 188.,  20.,   0.,   0.,   0.,\n",
       "         0.,   0., 109., 251., 253., 251.,  35.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  37., 251., 251.,\n",
       "       201.,  30.,   0.,   0.,   0.,   0.,   0.,   0.,  31., 200., 253.,\n",
       "       251.,  35.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  37., 253., 253.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  32., 202., 255., 253., 164.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 140., 251.,\n",
       "       251.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 109., 251.,\n",
       "       253., 251.,  35.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 217., 251., 251.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  21.,  63., 231., 251., 253., 230.,  30.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 217.,\n",
       "       251., 251.,   0.,   0.,   0.,   0.,   0.,   0., 144., 251., 251.,\n",
       "       251., 221.,  61.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 217., 251., 251.,   0.,   0.,   0.,\n",
       "         0.,   0., 182., 221., 251., 251., 251., 180.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       218., 253., 253.,  73.,  73., 228., 253., 253., 255., 253., 253.,\n",
       "       253., 253.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 113., 251., 251., 253., 251.,\n",
       "       251., 251., 251., 253., 251., 251., 251., 147.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  31., 230., 251., 253., 251., 251., 251., 251., 253., 230.,\n",
       "       189.,  35.,  10.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  62., 142., 253.,\n",
       "       251., 251., 251., 251., 253., 107.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  72., 174., 251., 173.,  71.,  72.,\n",
       "        30.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[3] * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 5.2832847e-13, 7.4402526e-11, 1.6595639e-13,\n",
       "        2.4564201e-14, 3.6019356e-15, 1.8585454e-09, 2.7845952e-09,\n",
       "        4.2733249e-16, 4.3519319e-10]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([x_test[3]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
